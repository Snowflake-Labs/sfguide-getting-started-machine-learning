{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e339e77",
   "metadata": {},
   "source": [
    "# SOLUTION: Model Building, Scoring & Evaluating (LightGBM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7d72538",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb04fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.types as T\n",
    "\n",
    "from snowflake.ml.modeling.lightgbm import LGBMClassifier\n",
    "from snowflake.ml.modeling.metrics import *\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11413743",
   "metadata": {},
   "source": [
    "## Create Snowpark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bad29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creds.json') as f:\n",
    "    connection_parameters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc080c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(connection_parameters).create()\n",
    "print(f\"Current Database and schema: {session.get_fully_qualified_current_schema()}\")\n",
    "print(f\"Current Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24d093ad",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sdf = session.table('CREDIT_RISK_PREPARED_BALANCED_TRAIN')\n",
    "test_sdf = session.table('CREDIT_RISK_PREPARED_BALANCED_TEST')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b36c435c",
   "metadata": {},
   "source": [
    "# SOLUTION: Train a LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = train_sdf.columns\n",
    "feature_cols.remove('TARGET')\n",
    "feature_cols.remove('ID')\n",
    "target_col = 'TARGET'\n",
    "\n",
    "lgbmodel = LGBMClassifier(\n",
    "    input_cols=feature_cols, \n",
    "    label_cols=target_col, \n",
    "    output_cols='PREDICTION'\n",
    "    )\n",
    "lgbmodel.fit(train_sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a438e",
   "metadata": {},
   "source": [
    "The fitted model can be retrieved as an XGB object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmodel_local = lgbmodel.to_lightgbm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedab745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "feat_importance = pd.DataFrame(lgbmodel_local.feature_importances_,lgbmodel_local.feature_name_,columns=['FeatImportance'])\n",
    "feat_importance.sort_values('FeatImportance').plot.barh(y='FeatImportance', figsize=(5,15))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19a60347",
   "metadata": {},
   "source": [
    "# Model Scoring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f2baa9c",
   "metadata": {},
   "source": [
    "# SOLUTION: Use the fitted LightGBM Model to score a Snowpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_sdf = lgbmodel.predict(test_sdf)\n",
    "scored_sdf.write.save_as_table(table_name='CREDIT_RISK_PREPARED_BALANCED_TEST_SCORED', mode='overwrite')\n",
    "session.table('CREDIT_RISK_PREPARED_BALANCED_TEST_SCORED').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8e7df",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a106a5",
   "metadata": {},
   "source": [
    "# Solution: Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acccuracy:', accuracy_score(df=scored_sdf, y_true_col_names='TARGET', y_pred_col_names='PREDICTION'))\n",
    "print('Precision:', precision_score(df=scored_sdf, y_true_col_names='TARGET', y_pred_col_names='PREDICTION'))\n",
    "print('Recall:', recall_score(df=scored_sdf, y_true_col_names='TARGET', y_pred_col_names='PREDICTION'))\n",
    "print('F1:', f1_score(df=scored_sdf, y_true_col_names='TARGET', y_pred_col_names='PREDICTION'))\n",
    "\n",
    "# Obtaining and plotting a simple confusion matrix\n",
    "cf_matrix = confusion_matrix(df=scored_sdf, y_true_col_name='TARGET', y_pred_col_name='PREDICTION')\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81857e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
